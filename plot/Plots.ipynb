{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'gs://REDACTED'\n",
    "network = 'resnet20'\n",
    "prune = 'global_magnitude_20'\n",
    "short_or_early = 'early'\n",
    "version = 'v2'\n",
    "early_idx = 40\n",
    "early_delta = 0\n",
    "train_steps = 71108\n",
    "batch_size = 50000/128\n",
    "all_prune_idxs = [0,4701,12514,20326,28139,35951,39858,43764,51576,59389,67201,71108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'gs://REDACTED'\n",
    "network = 'resnet50'\n",
    "prune = 'prune_global_20'\n",
    "short_or_early = 'short'\n",
    "version = 'v10'\n",
    "early_idx = 9\n",
    "early_delta = 9\n",
    "train_steps = 112590\n",
    "batch_size = 1251\n",
    "all_prune_idxs = [0, 11259, 22518, 33777, 45036, 56295, 67554, 78813, 90072, 101331, 112590]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 's3://REDACTED-data'\n",
    "network = 'vgg_16_nofc'\n",
    "prune = 'prune_global_20_fc'\n",
    "short_or_early = 'early'\n",
    "version = 'v2'\n",
    "early_idx = 40\n",
    "early_delta = 40\n",
    "train_steps = 71108\n",
    "batch_size = 50000/128\n",
    "all_prune_idxs = [0,4701,12514,20326,28139,35951,39858,43764,51576,59389,67201,71108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 's3://REDACTED-data'\n",
    "network = 'vgg_19'\n",
    "prune = 'prune_global_20_fc'\n",
    "short_or_early = 'early'\n",
    "version = 'v3'\n",
    "early_idx = 40\n",
    "early_delta = 40\n",
    "train_steps = 71108\n",
    "batch_size = 50000/128\n",
    "all_prune_idxs = [0,4701,12514,20326,28139,35951,39858,43764,51576,59389,67201,71108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "env = {\n",
    "    'AWS_REGION': 'us-standard',\n",
    "    'S3_ENDPOINT': 's3.us.cloud-object-storage.appdomain.cloud',\n",
    "    'AWS_ACCESS_KEY_ID': 'dcd241d33c7142d6b8a80251e05375fc',\n",
    "    'AWS_SECRET_ACCESS_KEY': 'd30074e169ee8aa885dba41819c247118e163878f47abc32',\n",
    "    'S3_USE_HTTPS': '1',\n",
    "    'S3_VERIFY_SSL': '0',\n",
    "}\n",
    "print('\\n'.join('export {}={}'.format(k, v) for (k, v) in env.items()))\n",
    "os.environ.update(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import utils\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "\n",
    "import gfile\n",
    "type_re = re.compile(r'.*?(finetune/finetune_(?P<ft_idx>\\d+)'\n",
    "                     r'|lottery/prune_(?P<prune_idx>\\d+)$'\n",
    "                     r'|lottery_(early|short)_(?P<early_epochs>\\d+)/prune_(?P<prune_early_idx>\\d+)$'\n",
    "                     r'|reinit/prune_(?P<reinit_idx>\\d+)$'\n",
    "                     r')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.iter_datum_of_iter_dir(('gs://REDACTED/results/resnet50/prune_global_20/v10/finetune/finetune_9/trial_1/iter_0', False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['{base}/results/{network}/{prune}/{version}/lottery/prune_{idx}'.format(\n",
    "    base=base,\n",
    "    network=network,\n",
    "    prune=prune,\n",
    "    version=version,\n",
    "    idx=p,\n",
    ") for p in all_prune_idxs]\n",
    "dirs += ['{base}/results/{network}/{prune}/{version}/finetune/finetune_{idx}'.format(\n",
    "    base=base,\n",
    "    network=network,\n",
    "    prune=prune,\n",
    "    version=version,\n",
    "    idx=int((train_steps - p) / batch_size),\n",
    ") for p in all_prune_idxs]\n",
    "dirs += ['{base}/results/{network}/{prune}/{version}/lottery_{short_or_early}_{early_idx}/prune_{idx}'.format(\n",
    "    base=base,\n",
    "    network=network,\n",
    "    prune=prune,\n",
    "    version=version,\n",
    "    short_or_early=short_or_early,\n",
    "    early_idx=early_idx,\n",
    "    idx=p,\n",
    ") for p in all_prune_idxs]\n",
    "dirs += ['{base}/results/{network}/{prune}/{version}/reinit/prune_{idx}'.format(\n",
    "    base=base,\n",
    "    network=network,\n",
    "    prune=prune,\n",
    "    version=version,\n",
    "    idx=p,\n",
    ") for p in all_prune_idxs]\n",
    "\n",
    "experiments = utils.experiments_of_directories(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(experiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in experiments:\n",
    "    for t in e.trial_data:\n",
    "        t.iter_data[:] = list(filter(lambda x: x is not None, t.iter_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in experiments:\n",
    "    for t in e.trial_data:\n",
    "        dname, rest = os.path.split(e.experiment_dir)\n",
    "        \n",
    "        iter_dir = os.path.join(os.path.dirname(dname), 'lottery', rest, t.trial, 'iter_0')\n",
    "        res = lambda: utils.iter_datum_of_iter_dir((\n",
    "            iter_dir,\n",
    "            False,\n",
    "        ))\n",
    "        \n",
    "        if len(t.iter_data) == 0 or 'finetune' in e.experiment_dir:\n",
    "            continue\n",
    "        if t.iter_data[0] is None:\n",
    "            print('fetching {}'.format(iter_dir))\n",
    "            t.iter_data[0] = res()\n",
    "        elif t.iter_data[0].iter != 'iter_0':\n",
    "            print('fetching {}'.format(iter_dir))\n",
    "            t.iter_data.insert(0, res())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_iter(expt, trial, iter_idx):\n",
    "    if isinstance(trial.iter_data, list):\n",
    "        iter_data = trial.iter_data\n",
    "    else:\n",
    "        iter_data = trial.iter_data.get()\n",
    "\n",
    "    iter_data = list(filter(lambda x: x is not None, iter_data))\n",
    "\n",
    "    try:\n",
    "        return next(i for i in iter_data if i.iter == 'iter_{}'.format(iter_idx))\n",
    "    except StopIteration:\n",
    "        return\n",
    "\n",
    "def get_expt(lottery, eps, early=False, reinit=False):\n",
    "    for expt in experiments:\n",
    "        m = type_re.match(expt.experiment_dir.rstrip('/'))\n",
    "\n",
    "        if m.group('reinit_idx') and reinit and eps == int(train_steps/batch_size - round(int(m.group('reinit_idx')) / batch_size)):\n",
    "            return expt\n",
    "        elif m.group('ft_idx') and not lottery and not reinit and eps == int(m.group('ft_idx')):\n",
    "            return expt\n",
    "        elif m.group('prune_idx') and lottery and not early and not reinit and eps == int(train_steps/batch_size - round(int(m.group('prune_idx')) / batch_size)):\n",
    "            return expt\n",
    "        elif m.group('prune_early_idx') and lottery and early and not reinit and eps == int(train_steps/batch_size - round(int(m.group('prune_early_idx')) / batch_size)):\n",
    "            return expt\n",
    "        \n",
    "def get_deltas(expt, it_from, it_to):\n",
    "    def _get(it):\n",
    "        data = {}\n",
    "        for t in expt.trial_data:\n",
    "            v = _get_iter(expt, t, it)\n",
    "            if v is None:\n",
    "                continue\n",
    "            data[t.trial] = v\n",
    "        return data\n",
    "    \n",
    "    from_ = _get(it_from)\n",
    "    to_ = _get(it_to)\n",
    "    \n",
    "    res = []\n",
    "    for k in set(from_.keys()) & set(to_.keys()):\n",
    "        if to_[k].test_acc is not None and from_[k].test_acc is not None:\n",
    "            res.append(to_[k].test_acc - from_[k].test_acc)\n",
    "    return np.array(res)\n",
    "\n",
    "def suffix_of_number(myDate):\n",
    "    date_suffix = [\"th\", \"st\", \"nd\", \"rd\"]\n",
    "\n",
    "    if myDate % 10 in [1, 2, 3] and myDate not in [11, 12, 13]:\n",
    "        return date_suffix[myDate % 10]\n",
    "    else:\n",
    "        return date_suffix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(1000)\n",
    "def _get_substeps(directory):\n",
    "    execution_data_iter_dir = os.path.join(directory, 'eval')\n",
    "    execution_data_iter_dir = execution_data_iter_dir.replace('REDACTED/results', 'REDACTED/execution_data')\n",
    "    events_file = next(x for x in gfile.ListDirectory(execution_data_iter_dir) if x.startswith('events.out'))\n",
    "\n",
    "    steps_xs = []\n",
    "    steps_ys = []\n",
    "    for e in tf.train.summary_iterator(os.path.join(execution_data_iter_dir, events_file)):\n",
    "        for v in e.summary.value:\n",
    "            if v.tag == 'accuracy':\n",
    "                steps_xs.append(e.step)\n",
    "                steps_ys.append(v.simple_value)\n",
    "\n",
    "    steps_xs = np.array(steps_xs) - (max(steps_xs) - train_steps)\n",
    "    steps_ys = np.array(steps_ys)\n",
    "    return steps_xs, steps_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "pool = multiprocessing.Pool(5)\n",
    "\n",
    "def get_substeps_of_expt_iter(expt, iter_idx, eps):\n",
    "    all_steps_xs = None\n",
    "    all_steps_ys = []\n",
    "    \n",
    "    dirs = [os.path.join(expt.experiment_dir, t.trial, 'iter_{}'.format(iter_idx)) for t in expt.trial_data]\n",
    "    for steps_xs, steps_ys in pool.map(_get_substeps, dirs):\n",
    "        if all_steps_xs is not None:\n",
    "            assert np.allclose(steps_xs, all_steps_xs)\n",
    "        all_steps_xs = steps_xs\n",
    "        \n",
    "        if all_steps_ys is None:\n",
    "            all_steps_ys = np.zeros_like(steps_ys)\n",
    "        all_steps_ys.append(steps_ys)\n",
    "        \n",
    "    ys =  np.array(all_steps_ys) - np.array([_get_iter(expt, t, 0).test_acc for t in expt.trial_data]).reshape(-1, 1)\n",
    "    return all_steps_xs / batch_size - (train_steps/batch_size - eps), ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "t20 = matplotlib.cm.get_cmap('tab20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(range(1, 10))\n",
    "import collections\n",
    "cumsum_p = collections.defaultdict(float)\n",
    "cumsum_f = collections.defaultdict(float)\n",
    "\n",
    "# plt.figure(figsize=(16, 4 * len(idxs)))\n",
    "# plt.figure(figsize=(8, 4 * len(idxs)))\n",
    "\n",
    "def get_centers(arr):\n",
    "    if center_type == 'mean':\n",
    "        return np.array([np.array(x).mean() for x in arr])\n",
    "    elif center_type == 'median':\n",
    "        return np.array([np.median(np.array(x)) for x in arr])\n",
    "    else:\n",
    "        raise ValueError('Unkown center type {}'.format(center_type))\n",
    "    \n",
    "def get_errors(arr):\n",
    "    if err_type == 'std':\n",
    "        return [np.array(x).std() for x in arr]\n",
    "    elif err_type == 'minmax':\n",
    "        centers = get_centers(arr)\n",
    "        mins = np.array([x.min() for x in arr])\n",
    "        maxs = np.array([x.max() for x in arr])\n",
    "        return np.stack([\n",
    "            centers - mins,\n",
    "            maxs - centers,\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError('Unknown err type {}'.format(err_type))\n",
    "        \n",
    "    \n",
    "def get_experiments_at_idx(idx):\n",
    "    prune_expts = {}\n",
    "    prune_early_expts = {}\n",
    "    ft_expts = {}\n",
    "    reinit_expts = {}\n",
    "\n",
    "    for expt in experiments:\n",
    "        m = type_re.match(expt.experiment_dir.rstrip('/'))\n",
    "        deltas = get_deltas(expt, 0, idx)\n",
    "        \n",
    "        if len(deltas) == 0:\n",
    "            continue\n",
    "            \n",
    "        if m.group('ft_idx'):\n",
    "            ft_expts[int(m.group('ft_idx'))] = deltas\n",
    "        elif m.group('prune_idx'):\n",
    "            prune_expts[int(train_steps/batch_size - round(int(m.group('prune_idx')) / batch_size))] = deltas\n",
    "        elif m.group('prune_early_idx'):\n",
    "            prune_early_expts[int(train_steps/batch_size - round(int(m.group('prune_early_idx')) / batch_size))] = deltas\n",
    "        elif m.group('reinit_idx'):\n",
    "            reinit_expts[int(train_steps/batch_size - round(int(m.group('reinit_idx')) / batch_size))] = deltas\n",
    "    return (prune_expts, prune_early_expts, ft_expts, reinit_expts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_type = 'mean'\n",
    "err_type = 'std'\n",
    "\n",
    "fmt_label = lambda x: '{} {} {}'.format(\n",
    "    x,\n",
    "    center_type,\n",
    "    r'$\\pm 1$ std' if err_type == 'std' else r'$\\pm$ $\\min$/$\\max$'\n",
    ")\n",
    "lot_label = fmt_label('Rewind')\n",
    "lot_early_label = fmt_label('Rewind & Early Stop')\n",
    "ft_label = fmt_label('Fine-tune')\n",
    "reinit_label = fmt_label('Scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(to_plot, save):\n",
    "    for sp_i, iter_idx in enumerate(idxs):\n",
    "        print(iter_idx)\n",
    "        (prune_expts, prune_early_expts, ft_expts, reinit_expts) = get_experiments_at_idx(iter_idx)\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.title(r'$\\Delta$ test accuracy after {idx}{suffix} pruning iteration (approx. {sparsity:.2%} sparsity)'.format(\n",
    "            idx=iter_idx,\n",
    "            suffix=suffix_of_number(iter_idx),\n",
    "            sparsity=1-.8**iter_idx,\n",
    "        ))\n",
    "        plt.ylabel('$\\Delta$ in test accuracy')\n",
    "        plt.xlabel('Re-training Epochs')\n",
    "\n",
    "        if to_plot['early']:\n",
    "            lot_early_xs, lot_early_deltas = zip(*sorted(list(prune_early_expts.items())))\n",
    "            lot_early_xs = lot_early_xs\n",
    "            lot_early_deltas = lot_early_deltas\n",
    "            \n",
    "            plt.errorbar(\n",
    "                np.array(lot_early_xs) - early_delta, \n",
    "                get_centers(lot_early_deltas),\n",
    "                get_errors(lot_early_deltas),\n",
    "                fmt='o--', \n",
    "                label=lot_early_label,\n",
    "                color='C0',\n",
    "            )\n",
    "\n",
    "        lot_xs, lot_deltas = zip(*sorted(list(prune_expts.items())))\n",
    "        if to_plot['rewind']:\n",
    "            plt.errorbar(\n",
    "                lot_xs, \n",
    "                get_centers(lot_deltas),\n",
    "                get_errors(lot_deltas),\n",
    "                fmt='o--', \n",
    "                label=lot_label,\n",
    "                color='C1',\n",
    "            )\n",
    "\n",
    "        ft_xs, ft_deltas = zip(*sorted(list(ft_expts.items())))\n",
    "        if to_plot['finetune']:\n",
    "            plt.errorbar(\n",
    "                ft_xs, \n",
    "                get_centers(ft_deltas),\n",
    "                get_errors(ft_deltas),\n",
    "                fmt='o--',\n",
    "                label=ft_label,\n",
    "                color='C2',\n",
    "            )\n",
    "\n",
    "        if to_plot['scratch'] and reinit_expts:\n",
    "            reinit_xs, reinit_deltas = zip(*sorted(list(reinit_expts.items())))\n",
    "            plt.errorbar(\n",
    "                reinit_xs, \n",
    "                get_centers(reinit_deltas),\n",
    "                get_errors(reinit_deltas),\n",
    "                fmt='o--',\n",
    "                label=reinit_label,\n",
    "                color='C3',\n",
    "            )\n",
    "\n",
    "\n",
    "        plt.plot([0, train_steps/batch_size], [0, 0], '--', color=(0,0,0,0.3))\n",
    "        plt.legend()\n",
    "        plt.ylim(-0.03, 0.01)\n",
    "        vals = plt.gca().get_yticks()\n",
    "        plt.gca().set_yticklabels(['{:+,.2%}'.format(x) for x in vals])\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save:\n",
    "            with gfile.Open('gs://REDACTED/figures/resnet20/{plots}-sparse-pidx-{pidx}.png'.format(\n",
    "                plots='-'.join(sorted([k for (k,v) in to_plot.items() if v])),\n",
    "                pidx=iter_idx\n",
    "            ), 'wb') as f:\n",
    "                plt.savefig(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "idxs = range(30)\n",
    "\n",
    "for (r,e,f,s) in itertools.product(*([[True, False]]*4)):\n",
    "    to_plot = {\n",
    "        'rewind': r,\n",
    "        'early': e,\n",
    "        'finetune': f,\n",
    "        'scratch': s,\n",
    "    }\n",
    "    if r and f and e and not (s):\n",
    "#     if r and not (s or e or f):\n",
    "        make_plots(to_plot, False)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[e for e in experiments if 'short' in e.experiment_dir and '67554' in e.experiment_dir][0].experiment_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[e for e in experiments if 'finetune_9' in e.experiment_dir][0].trial_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
